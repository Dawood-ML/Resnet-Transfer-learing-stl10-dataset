{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f43b66b",
   "metadata": {},
   "source": [
    "# STL10 Image Classification (PyTorch)\n",
    "\n",
    "\n",
    "This notebook trains:\n",
    "**ResNet18 (transfer learning)**\n",
    "\n",
    "Deliverables included:\n",
    "- Training/validation accuracy & loss plots\n",
    "- Confusion matrix\n",
    "- Sample predictions\n",
    "- Saved model weights\n",
    "\n",
    "**Dataset:** `STL10` (10 classes, 96x96 images). Labeled splits used: `train` (5k) and `test` (8k).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment & imports\n",
    "import os, time, math, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b3d4a",
   "metadata": {},
   "source": [
    "## 1) Data Loading\n",
    "- STL10 images are **96x96**.\n",
    "- For **Simple CNN**, we keep 96x96.\n",
    "- For **ResNet18**, we'll **resize to 224x224** later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241078f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_96 = (0.4467, 0.4398, 0.4066)\n",
    "std_96  = (0.2241, 0.2215, 0.2239)\n",
    "\n",
    "train_tf_96 = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean_96, std_96),\n",
    "])\n",
    "\n",
    "test_tf_96 = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean_96, std_96),\n",
    "])\n",
    "\n",
    "data_root = './data'\n",
    "\n",
    "train_ds_96 = STL10(root=data_root, split='train', download=True, transform=train_tf_96)\n",
    "test_ds_96  = STL10(root=data_root, split='test', download=True, transform=test_tf_96)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader_96 = DataLoader(train_ds_96, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader_96  = DataLoader(test_ds_96, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "class_names = train_ds_96.classes\n",
    "num_classes = len(class_names)\n",
    "num_classes, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df33147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img, mean=mean_96, std=std_96):\n",
    "    img = img.clone()\n",
    "    for c in range(3):\n",
    "        img[c] = img[c]*std[c] + mean[c]\n",
    "    return img.clamp(0,1)\n",
    "\n",
    "images, labels = next(iter(train_loader_96))\n",
    "plt.figure()\n",
    "grid = torchvision.utils.make_grid(denorm(images[:16]))\n",
    "plt.imshow(np.transpose(grid.numpy(), (1,2,0)))\n",
    "plt.title('Sample training images')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af18826",
   "metadata": {},
   "source": [
    "### MAking a training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criteria, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criteria(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()*x.size(0)\n",
    "        _, pred = out.max(1)\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return running_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299543b",
   "metadata": {},
   "source": [
    "### Creating an Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ad9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criteria):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criteria(out, y)\n",
    "            running_loss += loss.item()*x.size(0)\n",
    "            _, pred = out.max(1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    avg_loss = running_loss/total\n",
    "    acc = correct/total\n",
    "    return avg_loss, acc, torch.cat(all_preds), torch.cat(all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350511e4",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb493f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_224 = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "test_tf_224 = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "train_ds_224 = STL10(root=data_root, split='train', download=True, transform=train_tf_224)\n",
    "test_ds_224  = STL10(root=data_root, split='test', download=True, transform=test_tf_224)\n",
    "\n",
    "train_loader_224 = DataLoader(train_ds_224, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader_224  = DataLoader(test_ds_224, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "in_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(in_features, num_classes)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "criterion_res = nn.CrossEntropyLoss()\n",
    "optimizer_res = optim.Adam(resnet.parameters(), lr=1e-4)\n",
    "\n",
    "epochs_res = 6  # quick fine-tune\n",
    "history_res = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n",
    "best_acc_res, best_state_res = 0.0, None\n",
    "\n",
    "for ep in range(1, epochs_res+1):\n",
    "    tl, ta = train_one_epoch(resnet, train_loader_224, criterion_res, optimizer_res)\n",
    "    vl, va, _, _ = evaluate(resnet, test_loader_224, criterion_res)\n",
    "    history_res['train_loss'].append(tl)\n",
    "    history_res['train_acc'].append(ta)\n",
    "    history_res['val_loss'].append(vl)\n",
    "    history_res['val_acc'].append(va)\n",
    "    print(f\"[ResNet18] Epoch {ep}/{epochs_res}: train_loss={tl:.4f} train_acc={ta:.4f} | val_loss={vl:.4f} val_acc={va:.4f}\")\n",
    "    if va > best_acc_res:\n",
    "        best_acc_res = va\n",
    "        best_state_res = resnet.state_dict()\n",
    "\n",
    "if best_state_res is not None:\n",
    "    resnet.load_state_dict(best_state_res)\n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "    torch.save(resnet.state_dict(), 'checkpoints/stl10_resnet18.pt')\n",
    "    print('Best ResNet18 saved to checkpoints/stl10_resnet18.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9dee5",
   "metadata": {},
   "source": [
    "### Accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'history_res' in globals() and len(history_res['train_acc'])>0:\n",
    "    plt.figure()\n",
    "    plt.plot(history_res['train_acc'], label='train')\n",
    "    plt.plot(history_res['val_acc'], label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over epochs (ResNet18)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history_res['train_loss'], label='train')\n",
    "    plt.plot(history_res['val_loss'], label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over epochs (ResNet18)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('There is a problem with resnet. Fix it')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8b389",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'resnet' in globals():\n",
    "    vl, va, preds_res, labels_res = evaluate(resnet, test_loader_224, criterion_res)\n",
    "    cm_res = confusion_matrix(labels_res.numpy(), preds_res.numpy())\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm_res, interpolation='nearest')\n",
    "    plt.title('Confusion Matrix (ResNet18)')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    thresh = cm_res.max() / 2.\n",
    "    for i, j in itertools.product(range(cm_res.shape[0]), range(cm_res.shape[1])):\n",
    "        plt.text(j, i, cm_res[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_res[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('Classification Report (ResNet18):')\n",
    "    print(classification_report(labels_res.numpy(), preds_res.numpy(), target_names=class_names))\n",
    "else:\n",
    "    print('There is a problem with resnet. Fix it')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
